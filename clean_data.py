import pandas as pd
from nltk.corpus import stopwords
import nltk
import re

# ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î stopwords
nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

# ‡πÄ‡∏û‡∏¥‡πà‡∏° custom stopwords
custom_stopwords = {
    # ‡∏Ç‡πà‡∏≤‡∏ß‡πÅ‡∏•‡∏∞‡∏™‡∏∑‡πà‡∏≠
    "news", "update", "latest", "breaking", "read", "watch", "live", "video",
    "media", "outlet", "journal", "articles", "headline", "source", "coverage", "information",
    "say", "says", "said", "report", "reports", "reported",
    "announced", "introduced", "launch", "revealed", "expects",
    "statements", "highlighted", "unveiled", "discussed", "talk", "asks", "request",
    "today", "week", "now",
    "company", "group", "corporation", "organization", "firm", "business",
    "ltd", "inc", "co", "plc", "association", "partner", "entity", "owner",
    "market", "investment", "opportunity", "cost", "revenue",
    "u.s", "china", "europe", "asia", "india", "africa", "japan", "korea",
    "middle", "east", "north", "america", "latin",
    "province", "city", "region", "district", "country",
    "is", "will", "with", "for", "by", "on", "at", "in", "to",
    "and", "or", "that", "as", "during", "through", "along",
    "from", "above", "around", "of", "between", "under", "over",
    "products", "services", "materials", "solutions", "technologies", "construction", "building",
    "supply", "demand", "development", "design", "researchgate"
    "engineering", "value", "growth", "trend", "innovation", "technology",
    "cement", "industry", "s", "weak", "strat", "new"
    "smm", "made", "engineering", "sale", "travis", "perkins", "finding",
    "material", "insights", "german", "researchers", "prices", "start", "new"
    "driven", "forecast", "analysis", "launched", "study", "data", "reporting", "trends"
    "usd", "billion", "million", "cagr", "year", "years", "2030", "2035", "2025", "2031", "research"
}
stop_words.update(custom_stopwords)

# ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£/‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏•‡∏ö
remove_words = [
    "BBC", "DW", "ResearchGate", "Dezeen", "HowStuffWorks",
    "Power Line Magazine", "ET EnergyWorld", "trend", "promoting", "about", "About", "and", "use"
]

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏•‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£
def remove_companies(text):
    for word in remove_words:
        text = re.sub(rf"\b{re.escape(word)}\b", "", text)
    return re.sub(r"\s{2,}", " ", text).strip()

# ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå CSV
df = pd.read_csv("data/scrap.csv", header=0, encoding='utf-8-sig')
print("üìÑ Columns in file:", df.columns.tolist())

# ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ title ‡∏´‡∏£‡∏∑‡∏≠ keyword
df = df.dropna(subset=["title", "keyword"])

# ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
filtered_rows = []
for _, row in df.iterrows():
    title = str(row["title"]).lower()
    title = remove_companies(title)  # ‡∏•‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÅ‡∏õ‡∏•‡∏á lowercase
    keyword = row["keyword"]

    words = title.split()
    filtered = [word for word in words if word not in stop_words and word.isalpha()]
    filtered_title = " ".join(filtered)

    filtered_rows.append({
        "cleaned_title": filtered_title,
        "keyword": keyword
    })

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà
filtered_df = pd.DataFrame(filtered_rows)
filtered_df.to_csv("data/cleaned.csv", index=False, encoding="utf-8")
print("‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")