from serpapi import GoogleSearch
import pandas as pd
from datetime import datetime
import os

# üîë API Key ‡∏à‡∏≤‡∏Å serpapi.com
API_KEY = "15179a882a5e319597d7dcb0fa7a2e61516f3cfbca11839352ad2f5545f0b5aa"  # ‡πÉ‡∏™‡πà API Key ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà

# üîç ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏±‡∏™‡∏î‡∏∏‡∏Å‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏¢‡∏±‡πà‡∏á‡∏¢‡∏∑‡∏ô
QUERIES = [
    "sustainable construction materials",
    "eco friendly building materials",
    "construction materials Thailand",
    "green construction trends"
]


CSV_FILENAME = "construction_materials_serpapi.csv"

# üóÇ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ú‡πà‡∏≤‡∏ô GoogleSearch
def search_google(query, num_pages=3):
    all_data = []

    for page in range(num_pages):
        params = {
            "q": query,
            "api_key": API_KEY,
            "num": 10,  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤
            "start": page * 10  # ‡∏Ç‡πâ‡∏≤‡∏°‡∏´‡∏ô‡πâ‡∏≤‡πÑ‡∏õ
        }

        search = GoogleSearch(params)
        results = search.get_dict()
        organic = results.get("organic_results", [])

        data = []
        for item in organic:
            data.append({
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "query": query,
                "title": item.get("title"),
                "url": item.get("link"),
                "snippet": item.get("snippet", "")
            })

        print(f"‚úÖ Fetched {len(data)} results for: '{query}' (page {page + 1})")
        all_data.extend(data)

    return all_data

# üíæ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á CSV
def save_to_csv(data, filename=CSV_FILENAME):
    df_new = pd.DataFrame(data)

    if os.path.exists(filename):
        df_old = pd.read_csv(filename)
        df_all = pd.concat([df_old, df_new], ignore_index=True)
    else:
        df_all = df_new

    df_all.to_csv(filename, index=False)
    print(f"üíæ Saved {len(data)} rows to '{filename}'\n")

# üì• ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å query
all_results = []
for query in QUERIES:
    data = search_google(query, num_pages=5)  # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    all_results.extend(data)

# üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á CSV
if all_results:
    save_to_csv(all_results)
else:
    print("‚ö†Ô∏è No data fetched.")
